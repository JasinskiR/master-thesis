\section{Implementacje w C++ (OpenMP)}
\subsection{Struktura i organizacja kodu}
Implementacje C++ z OpenMP następują klasyczny wzorzec proceduralny wywodzący się z~oryginalnych implementacji w Fortranie:

% \begin{lstlisting}[language=Rust, caption={Implementacja benchmarku CG w języku Rust}, label={lst:cg_rust}]
% \begin{lstlisting}[language=Rust, caption={Struktura kodu benchmarków w języku Rust}, label={lst:rust_structure}]
\begin{lstlisting}[language=C++, style=VS2017,  style=VS2017, caption={Struktura kodu benchmarków w języku C++ z OpenMP}, label={lst:openmp_structure}]
// OpenMP: globalne zmienne + ręczne zarządzanie pamięcią
static double (*data) = (double*)malloc(sizeof(double) * SIZE);
static int (*indices) = (int*)malloc(sizeof(int) * SIZE);

int main(int argc, char **argv) {
    // OpenMP: proceduralny styl z globalnym stanem
    initialize_data();
    parallel_algorithm();
    
    // Ręczne czyszczenie pamięci
    free(data); free(indices);
}
\end{lstlisting}
\begin{itemize}
    \item Globalny stan - wszystkie dane przechowywane są jako zmienne globalne, co upraszcza współdzielenie zasobów pomiędzy wątkami.
    
    \item Styl proceduralny - funkcje operują bezpośrednio na globalnych strukturach danych, zgodnie z tradycyjnym podejściem programowania proceduralnego.
    
    \item Minimalna enkapsulacja - brak hermetyzacji danych i logiki prowadzi do luźnej struktury kodu oraz ograniczonej kontroli nad jego modyfikacjami.
    
    \item Kompatybilność wsteczna - zachowanie zgodności z kodem Fortran ułatwia migrację i integrację z istniejącymi systemami HPC.
    
    \item Warunkowa alokacja - możliwość wyboru pomiędzy alokacją statyczną a dynamiczną umożliwia dostosowanie strategii zarządzania pamięcią do charakterystyki platformy.
\end{itemize}
  
\subsection{Zarządzanie pamięcią}
\begin{lstlisting}[language=C++, style=VS2017,  caption={Zarządzanie pamięcią w benchmarkach C++ z OpenMP}, label={lst:openmp_memory}]
// Warunkowa strategia alokacji pamięci
#if defined(DO_NOT_ALLOCATE_ARRAYS_WITH_DYNAMIC_MEMORY_AND_AS_SINGLE_DIMENSION)
static int colidx[NZ];
static int rowstr[NA+1];
static double a[NZ];
static double x[NA+2];
#else
static int (*colidx)=(int*)malloc(sizeof(int)*(NZ));
static int (*rowstr)=(int*)malloc(sizeof(int)*(NA+1));
static double (*a)=(double*)malloc(sizeof(double)*(NZ));
static double (*x)=(double*)malloc(sizeof(double)*(NA+2));
#endif

int main(int argc, char **argv) {
    // Brak sprawdzania błędów alokacji
    // Brak jawnego zwalniania pamięci
    // Potencjalne wycieki pamięci przy wcześniejszym wyjściu
    
    // Warunkowe zwalnianie (jeśli w ogóle)
    #if !defined(DO_NOT_ALLOCATE_ARRAYS_WITH_DYNAMIC_MEMORY_AND_AS_SINGLE_DIMENSION)
    // Często brakuje free() calls
    #endif
}
\end{lstlisting}
\begin{itemize}
    \item Ręczne zarządzanie pamięcią - eksplicytne wywołania \texttt{malloc} i \texttt{free} bez wsparcia automatyzacji, co zwiększa ryzyko błędów programistycznych.
    
    \item Brak sprawdzania błędów alokacji - operacje przydziału pamięci mogą zakończyć się niepowodzeniem, a ich wyniki często nie są weryfikowane.
    
    \item Wycieki pamięci - brak gwarancji, że zaalokowane zasoby zostaną zwolnione, co prowadzi do stopniowego wzrostu zużycia pamięci.
    
    \item Niezdefiniowane zachowanie - możliwość wystąpienia błędów, takich jak użycie pamięci po jej zwolnieniu czy podwójne zwolnienie pamięci, które mogą prowadzić do niestabilności programu, naruszenia integralności danych lub poważnych luk w bezpieczeństwie.
    
    \item Przepełnienie bufora (buffer overflows) - brak automatycznego sprawdzania granic tablic sprzyja nadpisywaniu pamięci poza przydzielonym obszarem.
\end{itemize}
  
\subsection{Mechanizmy równoległości}
\begin{lstlisting}[language=C++, style=VS2017,  caption={Mechanizmy równoległości w benchmarkach C++ z OpenMP}, label={lst:openmp_parallelism}]
// OpenMP: dyrektywy kompilacyjne + ręczna synchronizacja  
void parallel_algorithm() {
    double sum = 0.0;
    
    // Równoległa redukcja z harmonogramowaniem
    #pragma omp parallel for reduction(+:sum) schedule(static)
    for (int i = 0; i < SIZE; i++) {
        sum += compute_element(i);
    }
    
    // Sekcja krytyczna dla operacji zespołowych
    #pragma omp parallel
    {
        #pragma omp critical
        {
            update_shared_state();
        }
    }
}
\end{lstlisting}
\begin{itemize}
    \item Oparte na dyrektywach - wykorzystanie konstrukcji \texttt{\#pragma} do deklaratywnego sterowania równoległością w kodzie źródłowym.
    
    \item Ręczna synchronizacja - konieczność samodzielnego zarządzania sekcjami krytycznymi, barierami oraz mechanizmami ochrony danych współdzielonych.
    
    \item Jawne planowanie - programista ma bezpośrednią kontrolę nad strategiami podziału pracy, takimi jak \texttt{static}, \texttt{dynamic} czy \texttt{guided}.
    
    \item Model oparty na wątkach - równoległość realizowana przez bezpośrednie zarządzanie wątkami systemowymi, co wpływa na wydajność i kontrolę niskopoziomową.
    
    \item Dojrzały ekosystem - bogaty zbiór dyrektyw, opcji konfiguracyjnych i narzędzi wspierających optymalizację oraz profilowanie programów równoległych.
\end{itemize}
  
\subsection{Specyfika benchmarku EP}
\begin{lstlisting}[language=C++, style=VS2017,  caption={Implementacja benchmarku EP w języku C++ z OpenMP}, label={lst:ep_openmp}]
// EP Benchmark: Embarrassingly Parallel + OpenMP
void ep_main() {
    double sx = 0.0, sy = 0.0;
    
    #pragma omp parallel
    {
        double qq[NQ] = {0.0}; // Thread-private histogram
        double local_sx = 0.0, local_sy = 0.0;
        
        #pragma omp for
        for (int k = 1; k <= NN; k++) {
            double x[2*NK];
            vranlc(2*NK, &seed, A, x); // Generate random numbers
            
            // Box-Muller transform
            for (int i = 0; i < NK; i++) {
                double x1 = 2.0 * x[2*i] - 1.0;
                double x2 = 2.0 * x[2*i+1] - 1.0;
                double t1 = x1*x1 + x2*x2;
                
                if (t1 <= 1.0) {
                    double t2 = sqrt(-2.0 * log(t1) / t1);
                    local_sx += x1 * t2;
                    local_sy += x2 * t2;
                }
            }
        }
        
        // OpenMP: explicit critical section for reduction
        #pragma omp critical
        {
            sx += local_sx; sy += local_sy;
        }
    }
}
\end{lstlisting}

\subsection{Specyfika benchmarku CG}
\begin{lstlisting}[language=C++, style=VS2017,  caption={Implementacja benchmarku CG w języku C++ z OpenMP}, label={lst:cg_openmp}]
// CG: Conjugate Gradient + OpenMP 
static double *a, *x, *p, *q, *r, *z;
static int *colidx, *rowstr;

void cg_iteration() {
    double rho, d = 0.0;
    
    // OpenMP: parallel sparse matrix-vector multiply
    #pragma omp parallel for
    for (int j = 0; j < nrows; j++) {
        double sum = 0.0;
        for (int k = rowstr[j]; k < rowstr[j+1]; k++) {
            sum += a[k] * p[colidx[k]];
        }
        q[j] = sum;
    }
    
    // OpenMP: parallel dot product with reduction
    #pragma omp parallel for reduction(+:d)
    for (int j = 0; j < ncols; j++) {
        d += p[j] * q[j];
    }
    
    // OpenMP: parallel vector updates
    double alpha = rho / d;
    #pragma omp parallel for reduction(+:rho)
    for (int j = 0; j < ncols; j++) {
        z[j] += alpha * p[j];
        r[j] -= alpha * q[j];
        rho += r[j] * r[j];
    }
}
\end{lstlisting}

\subsection{Specyfika benchmarku IS}
\begin{lstlisting}[language=C++, style=VS2017,  caption={Implementacja benchmarku IS w języku C++ z OpenMP}, label={lst:is_openmp}]
static void rank(/* parametry */) {
    // Parallel histogram construction
    #pragma omp parallel
    {
        int key_buff_ptr[MAX_KEY];
        
        #pragma omp for
        for (int i = 0; i < num_keys; i++) {
            key_buff_ptr[key_buff[i]]++;
        }
        
        // Complex synchronization for bucket sort
        #pragma omp barrier
        
        #pragma omp for
        for (int i = 0; i < num_buckets; i++) {
            // Redistribute keys
        }
    }
}
\end{lstlisting}