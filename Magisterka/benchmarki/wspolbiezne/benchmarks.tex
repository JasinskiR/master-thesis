\chapter{Porównanie międzyjęzykowe - programowanie współbieżne}

W ramach analizy programowania współbieżnego przeanalizowano implementacje wzorców producent-konsument oraz serwer echo w językach Rust i C++. Obie wersje korzystają z różnych podejść do zarządzania współbieżnością: Rust z biblioteką Tokio oraz C++ z mechanizmami standardowej biblioteki i rozszerzeniami języka C++20.

\section{Porównanie międzyjęzykowe}

\subsection{Struktura i organizacja kodu}

\begin{table}[H]
    \centering
    \caption{Porównanie aspektów struktury i organizacji kodu w implementacjach współbieżnych}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust (Tokio)} &
        \textbf{C++ (std::thread + epoll/kqueue)} \\
        \midrule
        Architektura &
        Sterowana zdarzeniami z asynchronicznym środowiskiem wykonawczym, tworzenie zadań &
        Wątek na połączenie + opcjonalna pętla zdarzeń \\
        \hline
        Enkapsulacja &
        Moduły, cechy, system własności &
        Klasy, szablony, przestrzenie nazw \\
        \hline
        Obsługa błędów &
        \texttt{Result<T,E>}, operator \texttt{?}, wymuszona propagacja &
        \texttt{std::optional}, wyjątki, kody \texttt{errno} \\
        \hline
        Asynchroniczność &
        \texttt{async/await}, \texttt{tokio::select!}, wbudowane środowisko wykonawcze &
        \texttt{std::async}, ręczne pętle zdarzeń (epoll/kqueue) \\
        \hline
        Bezpieczeństwo typów &
        Sprawdzanie własności w czasie kompilacji, cechy \texttt{Send/Sync} &
        Sprawdzanie w czasie wykonania, ręczna synchronizacja \\
        \hline
        Konfiguracja &
        Cargo.toml, flagi funkcjonalności \eng{feature flags} &
        CMake/Make, dyrektywy preprocesora \\
        \hline
        Zarządzanie zależnościami &
        Scentralizowane z crates.io &
        Zdecentralizowane, pakiety systemowe \\
        \bottomrule
    \end{tabularx}
\end{table}

Implementacja w języku Rust cechuje się większą spójnością architektoniczną dzięki wbudowanym mechanizmom asynchroniczności oraz systemowi cech \eng{traits}. C++ zapewnia większą elastyczność kosztem złożoności zarządzania zgodnością między różnymi wersjami standardu.


\subsection{Zarządzanie pamięcią}

\begin{table}[H]
    \centering
    \caption{Porównanie modeli zarządzania pamięcią w badanych implementacjach}
    \renewcommand{\arraystretch}{1.3}
    \begin{tabularx}{\textwidth}{lX X}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust} &
        \textbf{C++} \\
        \midrule
        Model podstawowy &
        Własność z automatycznym zwalnianiem; sprawdzanie pożyczania w czasie kompilacji &
        RAII z ręcznym zarządzaniem czasem życia obiektów \\
        \midrule
        Współdzielenie w wątkach &
        \texttt{Arc<T>} dla danych niemutowalnych, \texttt{Arc<Mutex<T>>} dla mutowalnych &
        \texttt{std::shared\_ptr<T>}, ręczne opakowanie muteksem \\
        \midrule
        Bezpieczeństwo pamięci &
        Gwarantowane na etapie kompilacji, eliminacja wyścigów danych &
        Błędy ujawniane w czasie wykonania; ryzyko użycia po zwolnieniu \\
        \midrule
        Zwalnianie zasobów &
        Automatyczne dzięki cechom \texttt{Drop} &
        Destruktory RAII, często konieczne jawne zwolnienie (np. \texttt{close()}) \\
        \midrule
        Pomiar pamięci &
        Ograniczony dostęp do systemu plików \texttt{/proc} &
        Pełna analiza wykorzystania pamięci (RSS, sterta) \\
        \midrule
        Zarządzanie buforami &
        Bezpieczne wskaźniki i struktury (\texttt{Vec<T>}, \texttt{slice}) ze sprawdzaniem granic &
        Surowe wskaźniki i tablice, ryzyko przepełnień \\
        \midrule
        Porządek pamięci &
        \texttt{Ordering::Relaxed}, \texttt{Acquire}, \texttt{Release} &
        Odpowiedniki w \texttt{std::memory\_order} \\
        \midrule
        Wykrywanie wycieków &
        Rzadkie (np. cykliczne referencje z \texttt{Arc}); wspierane przez system typów &
        Częsty problem, wymagane zewnętrzne narzędzia (np. Valgrind) \\
        \bottomrule
    \end{tabularx}
\end{table}



System własności w języku Rust eliminuje całe klasy błędów pamięciowych na etapie kompilacji. C++ wymaga większej ostrożności programisty oraz wykorzystania narzędzi diagnostycznych.

\subsection{Mechanizmy współbieżności}

\begin{table}[H]
    \centering
    \caption{Porównanie mechanizmów współbieżności w badanych implementacjach}
    \renewcommand{\arraystretch}{1.3}
    \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X}
        \toprule
        \textbf{Mechanizm} &
        \textbf{Rust (Tokio)} &
        \textbf{C++ (std + wywołania systemowe)} \\
        \midrule
        Model wykonania &
        Wątki M:N z planistą opartym na kradzieży zadań (work-stealing scheduler) &
        Wątki 1:1 zarządzane przez systemowy planista \\
        \midrule
        Tworzenie zadań &
        \texttt{tokio::spawn(async move \{\})} – lekki i szybki sposób uruchamiania zadań asynchronicznych &
        \texttt{std::thread::spawn()} z opcjonalnym \texttt{.detach()} lub synchronizacją przez \texttt{join()} \\
        \midrule
        Komunikacja &
        Kanały wieloproducent–pojedynczykonsument: \texttt{mpsc::channel} z \texttt{Arc<Mutex<Receiver>>} &
        Własna implementacja \texttt{Channel<T>} oparta na \texttt{std::condition\_variable} \\
        \midrule
        Synchronizacja &
        Primitives: \texttt{tokio::sync::Mutex}, \texttt{Semaphore}, \texttt{RwLock} – dostosowane do async &
        Klasyczne prymitywy: \texttt{std::mutex}, \texttt{condition\_variable}, atomiki z \texttt{std::atomic} \\
        \midrule
        Operacje wejścia/wyjścia &
        Nieblokujące I/O z użyciem await, np. \texttt{TcpListener::bind().await} &
        Blokujące systemowe wywołania: \texttt{accept()}, \texttt{recv()}, \texttt{send()} \\
        \midrule
        Obsługa zdarzeń &
        Asynchroniczne makro \texttt{tokio::select!} do oczekiwania na wiele zdarzeń &
        Ręczne pętle zdarzeń z wykorzystaniem \texttt{epoll\_wait()} lub \texttt{kevent()} \\
        \midrule
        Ograniczenia zasobów &
        Semafory asynchroniczne, np. \texttt{Semaphore::try\_acquire\_owned()} &
        Własne liczniki z użyciem \texttt{std::atomic<size\_t>} \\
        \midrule
        Koordynacja zamknięcia &
        Kanały rozgłoszeniowe, np. \texttt{broadcast::channel} z łagodnym zamykaniem (graceful shutdown) &
        Flagi typu \texttt{std::atomic<bool>} sygnalizujące zakończenie wątku \\
        \midrule
        Zapobieganie wyścigom danych &
        Zapewnione na etapie kompilacji przez ograniczenia traitów \texttt{Send} i \texttt{Sync} &
        Potrzebna synchronizacja ręczna; ryzyko błędów wykonawczych i wyścigów danych \\
        \bottomrule
    \end{tabularx}
\end{table}


Porównując mechanizmy współbieżności w językach Rust i C++, można zauważyć fundamentalne różnice w filozofii projektowej i gwarancjach bezpieczeństwa. Rust przyjmuje podejście "bezpieczeństwo przede wszystkim", podczas gdy C++ oferuje większą elastyczność, ale wymaga większej dyscypliny od programisty.

\subsubsection{Rust - kanały typowane}
Implementacja Rust wykorzystuje kanały z różnymi semantykami komunikacji (\texttt{broadcast}):
\begin{lstlisting}[language=Rust, caption={Producent-Konsument w Rust z mpsc channels}, label={lst:rust_producer_consumer}]
fn producer_consumer_channel_benchmark(num_producers: usize, num_consumers: usize, items_per_producer: usize) {
    let metrics = Arc::new(ConcurrencyMetrics::new());
    let (tx, rx) = mpsc::channel();
    let rx = Arc::new(Mutex::new(rx));
    let producers_done = Arc::new(AtomicBool::new(false));
    
    // Producenci
    for i in 0..num_producers {
        let tx = tx.clone();
        let metrics_clone = Arc::clone(&metrics);
        
        let handle = thread::spawn(move || {
            for j in 0..items_per_producer {
                let start_send = Instant::now();
                if tx.send(format!("Producer-{}-Item-{}", i, j)).is_ok() {
                    metrics_clone.increment_produced();
                    metrics_clone.record_channel_operation(start_send.elapsed());
                }
                
                if j % 100 == 0 {
                    thread::sleep(Duration::from_micros(1));
                }
            }
            println!("Rust Producer {} finished", i);
        });
        producer_handles.push(handle);
    }
    
    // Konsumenci
    for i in 0..num_consumers {
        let rx = Arc::clone(&rx);
        let metrics_clone = Arc::clone(&metrics);
        let producers_done_clone = Arc::clone(&producers_done);
        
        let handle = thread::spawn(move || {
            let mut local_consumed = 0;
            loop {
                let start_recv = Instant::now();
                let received = {
                    if let Ok(rx_guard) = rx.try_lock() {
                        match rx_guard.try_recv() {
                            Ok(_item) => {
                                metrics_clone.record_channel_operation(start_recv.elapsed());
                                metrics_clone.increment_consumed();
                                local_consumed += 1;
                                true
                            }
                            Err(mpsc::TryRecvError::Empty) => {
                                if producers_done_clone.load(Ordering::Relaxed) {
                                    break;
                                }
                                false
                            }
                            Err(mpsc::TryRecvError::Disconnected) => break,
                        }
                    } else {
                        false
                    }
                };
                
                if !received {
                    thread::sleep(Duration::from_micros(10));
                }
            }
            println!("Rust Consumer {} finished, consumed {} items", i, local_consumed);
        });
        consumer_handles.push(handle);
    }
    
    drop(tx);
    for handle in producer_handles {
        handle.join().unwrap();
    }
    
    producers_done.store(true, Ordering::Relaxed);
    for handle in consumer_handles {
        handle.join().unwrap();
    }
}
\end{lstlisting}

\subsubsection{C++ - ręczna synchronizacja}
Wersja C++ opiera się na ręcznym zarządzaniu współbieżnością z użyciem mutexów i zmiennych warunkowych:
\begin{lstlisting}[language=C++, caption={Producent-Konsument w C++ z Channel}, label={lst:cpp_producer_consumer}]
template<typename T>
class Channel {
private:
    std::queue<T> queue_;
    mutable std::mutex mutex_;
    std::condition_variable condition_;
    bool closed_ = false;

public:
    void send(T item) {
        std::lock_guard<std::mutex> lock(mutex_);
        if (!closed_) {
            queue_.push(std::move(item));
            condition_.notify_one();
        }
    }

    bool try_recv(T& item) {
        std::unique_lock<std::mutex> lock(mutex_);
        if (queue_.empty()) {
            if (closed_) return false;
            return false;
        }
        item = std::move(queue_.front());
        queue_.pop();
        return true;
    }

    bool recv(T& item) {
        std::unique_lock<std::mutex> lock(mutex_);
        condition_.wait(lock, [this]() { return !queue_.empty() || closed_; });
        
        if (queue_.empty() && closed_) return false;
        
        item = std::move(queue_.front());
        queue_.pop();
        return true;
    }

    void close() {
        std::lock_guard<std::mutex> lock(mutex_);
        closed_ = true;
        condition_.notify_all();
    }
};

void enhanced_producer_consumer_channel_benchmark(std::size_t num_producers, std::size_t num_consumers, std::size_t items_per_producer) {
    auto metrics = std::make_shared<EnhancedConcurrencyMetrics>();
    Channel<std::string> channel;
    std::atomic<bool> producers_done{false};
    
    std::vector<std::thread> producers;
    std::vector<std::thread> consumers;
    
    // Producenci
    for (std::size_t i = 0; i < num_producers; ++i) {
        producers.emplace_back([i, items_per_producer, &channel, metrics]() {
            for (std::size_t j = 0; j < items_per_producer; ++j) {
                auto start_send = std::chrono::steady_clock::now();
                std::string item = "Producer-" + std::to_string(i) + "-Item-" + std::to_string(j);
                channel.send(item);
                metrics->increment_produced();
                auto end_send = std::chrono::steady_clock::now();
                metrics->record_channel_operation(std::chrono::duration_cast<std::chrono::nanoseconds>(end_send - start_send));
                
                if (j % 100 == 0) {
                    std::this_thread::sleep_for(std::chrono::microseconds(1));
                }
            }
            std::cout << "C++ Enhanced Producer " << i << " finished\n";
        });
    }
    
    // Konsumenci
    for (std::size_t i = 0; i < num_consumers; ++i) {
        consumers.emplace_back([i, &channel, &producers_done, metrics]() {
            std::string item;
            std::size_t local_consumed = 0;
            
            while (true) {
                auto start_recv = std::chrono::steady_clock::now();
                bool received = channel.try_recv(item);
                
                if (received) {
                    auto end_recv = std::chrono::steady_clock::now();
                    metrics->record_channel_operation(std::chrono::duration_cast<std::chrono::nanoseconds>(end_recv - start_recv));
                    metrics->increment_consumed();
                    local_consumed++;
                } else {
                    if (producers_done.load() && channel.empty()) {
                        break;
                    }
                    std::this_thread::sleep_for(std::chrono::microseconds(10));
                }
            }
            std::cout << "C++ Enhanced Consumer " << i << " finished, consumed " << local_consumed << " items\n";
        });
    }
    
    for (auto& t : producers) t.join();
    producers_done.store(true);
    
    std::this_thread::sleep_for(std::chrono::milliseconds(10));
    
    for (auto& t : consumers) t.join();
}
\end{lstlisting}

\subsubsection{Serwera echo}

\subsubsection{Rust - wejście/wyjście sterowane zdarzeniami}
Implementacja Rust wykorzystuje nieblokujące I/O:
\begin{lstlisting}[language=Rust, caption={Echo Serwer w Rust z Tokio}, label={lst:rust_echo_server}]
async fn run_echo_server(
    addr: &str, 
    max_connections: usize,
    shutdown_rx: &mut broadcast::Receiver<()>
) -> Arc<EchoServerMetrics> {
    println!("Starting echo server on {}", addr);
    
    let listener = TcpListener::bind(addr).await.expect("Failed to bind");
    let metrics = Arc::new(EchoServerMetrics::new());
    let semaphore = Arc::new(Semaphore::new(max_connections));
    
    println!("Echo server listening on {} (max {} connections)", addr, max_connections);
    
    loop {
        tokio::select! {
            // Handle new connections
            accept_result = listener.accept() => {
                match accept_result {
                    Ok((stream, addr)) => {
                        if let Ok(permit) = semaphore.clone().try_acquire_owned() {
                            let metrics_clone = Arc::clone(&metrics);
                            tokio::spawn(async move {
                                handle_echo_client(stream, addr, metrics_clone).await;
                                drop(permit);
                            });
                        } else {
                            println!("Connection rejected: max capacity reached");
                            drop(stream);
                        }
                    }
                    Err(e) => {
                        eprintln!("Failed to accept connection: {}", e);
                    }
                }
            }
            
            // Handle shutdown signal
            _ = shutdown_rx.recv() => {
                println!("Echo server shutting down...");
                break;
            }
        }
    }
    
    metrics
}

async fn handle_echo_client(
    mut stream: TcpStream, 
    addr: SocketAddr, 
    metrics: Arc<EchoServerMetrics>
) {
    let connection_start = Instant::now();
    let conn_id = metrics.connection_started();
    let mut buffer = [0; 1024];
    let mut total_bytes = 0u64;
    let mut message_count = 0;
    
    println!("Client connected: {} (ID: {})", addr, conn_id);
    
    loop {
        match timeout(Duration::from_secs(30), stream.read(&mut buffer)).await {
            Ok(Ok(0)) => break, // Connection closed
            Ok(Ok(n)) => {
                // Echo the data back
                if stream.write_all(&buffer[0..n]).await.is_err() {
                    break;
                }
                total_bytes += (n * 2) as u64; // Read + write
                message_count += 1;
            }
            Ok(Err(_)) | Err(_) => break, // Error or timeout
        }
    }
    
    let duration = connection_start.elapsed();
    metrics.connection_ended(duration, message_count, total_bytes);
    println!("Client disconnected: {} (ID: {}, {}ms, {} messages, {} bytes)", 
             addr, conn_id, duration.as_millis(), message_count, total_bytes);
}
\end{lstlisting}

\subsubsection{C++ - jeden wątek na połączenie}
Wersja C++ tworzy osobny wątek dla każdego klienta:
\begin{lstlisting}[language=C++, caption={Echo Serwer w C++ z jednym wątkiem na połączenie}, label={lst:cpp_echo_server}]
class EchoServer {
private:
    int server_socket;
    std::atomic<bool> running{true};
    std::shared_ptr<EchoServerMetrics> metrics;
    size_t max_connections;
    std::atomic<size_t> current_connections{0};

public:
    EchoServer(const std::string& address, int port, size_t max_conn) 
        : max_connections(max_conn), metrics(std::make_shared<EchoServerMetrics>()) {
        
        server_socket = socket(AF_INET, SOCK_STREAM, 0);
        if (server_socket < 0) {
            throw std::runtime_error("Failed to create socket");
        }
        
        int opt = 1;
        setsockopt(server_socket, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
        
        sockaddr_in server_addr{};
        server_addr.sin_family = AF_INET;
        server_addr.sin_port = htons(port);
        inet_pton(AF_INET, address.c_str(), &server_addr.sin_addr);
        
        if (bind(server_socket, (sockaddr*)&server_addr, sizeof(server_addr)) < 0) {
            throw std::runtime_error("Failed to bind socket");
        }
        
        if (listen(server_socket, SOMAXCONN) < 0) {
            throw std::runtime_error("Failed to listen on socket");
        }
    }
    
    void run() {
        std::cout << "Echo server listening (max " << max_connections << " connections)\n";
        
        while (running.load(std::memory_order_relaxed)) {
            sockaddr_in client_addr{};
            socklen_t addr_len = sizeof(client_addr);
            
            int client_socket = accept(server_socket, (sockaddr*)&client_addr, &addr_len);
            if (client_socket < 0) {
                if (running.load(std::memory_order_relaxed)) {
                    std::cerr << "Failed to accept connection\n";
                }
                continue;
            }
            
            if (current_connections.load(std::memory_order_relaxed) >= max_connections) {
                std::cout << "Connection rejected: max capacity reached\n";
                close(client_socket);
                continue;
            }
            
            char client_ip[INET_ADDRSTRLEN];
            inet_ntop(AF_INET, &client_addr.sin_addr, client_ip, INET_ADDRSTRLEN);
            std::string client_address = std::string(client_ip) + ":" + std::to_string(ntohs(client_addr.sin_port));
            
            std::thread(&EchoServer::handle_client, this, client_socket, client_address).detach();
        }
    }
    
    void handle_client(int client_socket, const std::string& client_addr) {
        auto connection_start = steady_clock::now();
        auto conn_id = metrics->connection_started();
        current_connections.fetch_add(1, std::memory_order_relaxed);
        
        char buffer[1024];
        uint64_t total_bytes = 0;
        size_t message_count = 0;
        
        std::cout << "Client connected: " << client_addr << " (ID: " << conn_id << ")\n";
        
        while (running.load(std::memory_order_relaxed)) {
            ssize_t bytes_read = recv(client_socket, buffer, sizeof(buffer), 0);
            if (bytes_read <= 0) break;
            
            ssize_t bytes_sent = send(client_socket, buffer, bytes_read, 0);
            if (bytes_sent <= 0) break;
            
            total_bytes += bytes_read + bytes_sent;
            message_count++;
        }
        
        auto duration = duration_cast<microseconds>(steady_clock::now() - connection_start);
        metrics->connection_ended(duration, message_count, total_bytes);
        current_connections.fetch_sub(1, std::memory_order_relaxed);
        
        std::cout << "Client disconnected: " << client_addr 
                  << " (ID: " << conn_id 
                  << ", " << duration_cast<milliseconds>(duration).count() << "ms"
                  << ", " << message_count << " messages"
                  << ", " << total_bytes << " bytes)\n";
        
        close(client_socket);
    }
};
\end{lstlisting}

\subsubsection{C++ - wersja asynchroniczna z epoll/kqueue}
C++ oferuje także asynchroniczną implementację używającą \texttt{epoll} (Linux) lub \texttt{kqueue} \mbox{(macOS)}:
\begin{lstlisting}[language=C++, caption={Async Echo Serwer w C++ z event loop}, label={lst:cpp_async_echo_server}]
class AsyncEchoServer {
private:
    int server_socket;
    std::atomic<bool> running{true};
    std::shared_ptr<EchoServerMetrics> metrics;
    size_t max_connections;
    std::atomic<size_t> current_connections{0};
    
#ifdef __APPLE__
    int kqueue_fd;
#else
    int epoll_fd;
#endif

public:
    void run_async() {
        std::cout << "Async Echo server listening (max " << max_connections << " connections)\n";
        
        while (running.load(std::memory_order_relaxed)) {
            std::vector<int> clients_to_remove;
            
#ifdef __APPLE__
            struct kevent events[64];
            struct timespec timeout = {0, 1000000}; // 1ms
            int nev = kevent(kqueue_fd, nullptr, 0, events, 64, &timeout);
            
            for (int i = 0; i < nev; ++i) {
                if ((int)events[i].ident == server_socket) {
                    // New connection
                    sockaddr_in client_addr{};
                    socklen_t addr_len = sizeof(client_addr);
                    
                    int client_socket = accept(server_socket, (sockaddr*)&client_addr, &addr_len);
                    if (client_socket >= 0) {
                        if (current_connections.load(std::memory_order_relaxed) >= max_connections) {
                            std::cout << "Async connection rejected: max capacity reached\n";
                            close(client_socket);
                            continue;
                        }
                        
                        // Set non-blocking
                        int flags = fcntl(client_socket, F_GETFL, 0);
                        fcntl(client_socket, F_SETFL, flags | O_NONBLOCK);
                        
                        // Add to kqueue
                        struct kevent ev;
                        EV_SET(&ev, client_socket, EVFILT_READ, EV_ADD, 0, 0, nullptr);
                        kevent(kqueue_fd, &ev, 1, nullptr, 0, nullptr);
                        
                        // Track connection
                        auto conn_id = metrics->connection_started();
                        current_connections.fetch_add(1, std::memory_order_relaxed);
                    }
                }
            }
#else
            struct epoll_event events[64];
            int nfds = epoll_wait(epoll_fd, events, 64, 1); // 1ms timeout
            
            for (int i = 0; i < nfds; ++i) {
                if (events[i].data.fd == server_socket) {
                    // Handle new connection similar to kqueue version
                } else {
                    // Handle client data
                    int client_socket = events[i].data.fd;
                    
                    if (!handle_client_data(client_socket)) {
                        epoll_ctl(epoll_fd, EPOLL_CTL_DEL, client_socket, nullptr);
                        disconnect_client(client_socket);
                        clients_to_remove.push_back(client_socket);
                    }
                }
            }
#endif
        }
    }
    
    bool handle_client_data(int client_socket) {
        char buffer[1024];
        ssize_t bytes_read = recv(client_socket, buffer, sizeof(buffer), 0);
        
        if (bytes_read > 0) {
            ssize_t bytes_sent = send(client_socket, buffer, bytes_read, 0);
            if (bytes_sent > 0) {
                return true; // Continue processing
            } else {
                return false; // Send failed, disconnect
            }
        } else if (bytes_read == 0 || (bytes_read < 0 && errno != EAGAIN && errno != EWOULDBLOCK)) {
            // Connection closed or error
            return false;
        }
        return true; // EAGAIN/EWOULDBLOCK, continue processing
    }
};
\end{lstlisting}

\subsection{Wydajność i bezpieczeństwo}

\begin{table}[H]
    \centering
    \caption{Porównanie wydajności i bezpieczeństwa implementacji współbieżnych}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust} &
        \textbf{C++} \\
        \midrule
        Bezpieczeństwo kompilacji &
        Wysokie - system pożyczania eliminuje wyścigi danych &
        Średnie - wymaga zewnętrznych narzędzi (np. ThreadSanitizer) \\
        \hline
        Narzut w czasie wykonania &
        Niski - abstrakcje bezkosztowe \eng{zero-cost} &
        Średni - narzut tworzenia wątków \\
        \hline
        Efektywność pamięci &
        Wysoka - współdzielona własność z \texttt{Arc<T>} &
        Średnia - ryzyko wycieków pamięci \\
        \hline
        Skalowanie &
        Wysokie - model M:N, kradzież zadań &
        Ograniczone - model 1:1, ograniczenia systemowe \\
        \hline
        Odzyskiwanie po błędach &
        Strukturalne - propagacja błędów przez \texttt{Result<T, E>} &
        Oparte na wyjątkach - ryzyko wycieków zasobów \\
        \hline
        Trudność debugowania &
        Średnia - błędy kompilacji z \eng{borrow checker} &
        Wysoka - wyścigi, błędy pamięci \\
        \hline
        Dojrzałość ekosystemu &
        Rozwijający się - Tokio, async-std &
        Dojrzały - OpenMP, TBB, Boost.Asio \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsection{Modele wykonania i zarządzanie zadaniami}

Implementacja Rust wykorzystuje bibliotekę Tokio, która dostarcza model wątków M:N z planistą kradzieży zadań. W praktyce oznacza to, że liczba wątków systemu operacyjnego jest niezależna od liczby zadań aplikacyjnych. Funkcja \texttt{tokio::spawn()} tworzy lekkie zadania zarządzane przez środowisko wykonawcze, co umożliwia efektywne wykorzystanie zasobów przy dużej liczbie współbieżnych operacji.

Implementacja C++ opiera się na modelu 1:1, gdzie każde połączenie obsługiwane jest przez dedykowany wątek systemu operacyjnego. Alternatywna wersja asynchroniczna wykorzystuje wywołania systemowe \texttt{epoll()} na Linux lub \texttt{kevent()} na macOS do implementacji pętli zdarzeń, jednak wymaga to jawnego zarządzania stanem połączeń.

\subsubsection{Komunikacja i synchronizacja}

W implementacji Rust komunikacja realizowana jest przez \texttt{mpsc::channel()} w konfiguracji \texttt{Arc<Mutex<Receiver<T> > >} dla wielu odbiorców. Kanał zapewnia bezpieczeństwo typów i automatyczne sprzątanie przy zamknięciu wszystkich nadawców.

Implementacja C++ definiuje własną klasę \texttt{Channel<T>} opartą na \texttt{std::queue} z synchronizacją przez \texttt{std::mutex} i \texttt{std::condition\_variable}. Klasa implementuje metody \texttt{send()}, \texttt{try\_recv()} oraz \texttt{recv()} z semantyką blokującą, wymagając ręcznego zarządzania stanem zamknięcia kanału.

\subsubsection{Obsługa I/O}

Rust wykorzystuje \texttt{TcpListener::bind().await} z nieblokującymi operacjami \mbox{wejścia/wyjścia}. Makro \texttt{tokio::select!} umożliwia równoległe oczekiwanie na wiele zdarzeń (nowe połączenia, sygnał zamknięcia). Ograniczenia połączeń realizowane są przez \texttt{Semaphore::try\_acquire\_owned()}.

C++ implementuje blokujące wejście/wyjście przez bezpośrednie wywołania systemowe: \texttt{socket()}, \texttt{bind()}, \texttt{listen()}, \texttt{accept()}. Każde połączenie obsługiwane jest w dedykowanym wątku z synchronicznymi operacjami \texttt{recv()}/\texttt{send()}. Wersja asynchroniczna wymaga ręcznego zarządzania stanem dla każdego deskryptora pliku.

\subsection{Zarządzanie błędami i zasobami}

Rust wymusza jawną obsługę błędów przez typy \texttt{Result<T, E>} i operator \texttt{?}. Automatyczne sprzątanie zasobów zapewniany jest przez cechę \texttt{Drop} - połączenia gniazd, alokacje pamięci oraz uchwyty wątków są automatycznie zwalniane.

C++ opiera się na wzorcu RAII z ręcznymi wywołaniami destruktorów. Sprzątanie gniazd wymaga explicite wywołań \texttt{close()}, a obsługa błędów realizowana jest przez rzucanie wyjątków lub sprawdzanie \texttt{errno}. Wycieki pamięci mogą wystąpić przy nieprawidłowym zarządzaniu cyklem życia objektów.


\subsubsection{Bezpieczeństwo współbieżności}

Najbardziej zasadnicza różnica między Rust a C++ dotyczy podejścia do bezpieczeństwa współbieżnego. Rust stosuje rygorystyczny system typów oraz cechy \texttt{Send} i \texttt{Sync}, które gwarantują bezpieczeństwo dostępu do danych współdzielonych już na etapie kompilacji. Kompilator odrzuca programy mogące prowadzić do wyścigów danych, co eliminuje całą klasę trudnych do wykrycia błędów.

W C++ bezpieczeństwo współbieżności opiera się na odpowiedzialności programisty. Wszelkie błędy synchronizacji (np. brak blokady, nadmierne współdzielenie danych) mogą prowadzić do wyścigów, które są trudne do wykrycia i debugowania. Choć dostępne są narzędzia analityczne, takie jak ThreadSanitizer, nie eliminują one problemów przed uruchomieniem programu i nie oferują gwarancji podobnych do Rust.



\subsection{Wnioski}

Analiza rzeczywistych implementacji ujawnia konkretne kompromisy między językami w kontekście programowania współbieżnego.
Rust z Tokio charakteryzuje się:
\begin{itemize}
    \item Bezpieczeństwem w czasie kompilacji przez system własności i cechy \texttt{Send/Sync}
    \item Architekturą sterowaną zdarzeniami z efektywnym wykorzystaniem zasobów
    \item Wymuszonym obsługą błędów eliminującym ciche awarie \eng{silent failures}
    \item Ograniczonymi możliwościami introspekcji środowiska wykonawczego
    \item Zależnością od zewnętrznych pakietów \eng{external crates} dla podstawowej funkcjonalności
\end{itemize}

C++ ze standardową biblioteką oferuje:
\begin{itemize}
    \item Bezpośrednią kontrolę nad zasobami systemowymi i układem pamięci
    \item Kompleksowe monitorowanie i profilowanie w czasie wykonania  
    \item Kompatybilność międzyplatformową z ręcznymi abstrakcjami platformowymi
    \item Model wątek na połączenie z przewidywalnym użyciem zasobów
    \item Ryzyko błędów w czasie wykonania wymagające ostrożnej synchronizacji
\end{itemize}

W praktyce wybór między językami zależy od priorytetów projektu: bezpieczeństwo a~kontrola, produktywność a elastyczność, nowoczesność a kompatybilność. Należy również uwzględnić kompetencje zespołu oraz wymagania środowiska docelowego.


