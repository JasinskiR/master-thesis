\chapter{Porównanie międzyjęzykowe - programowanie współbieżne}

W ramach analizy programowania współbieżnego przeanalizowano implementacje wzorców producent-konsument oraz serwer echo w językach Rust i C++. Obie wersje korzystają z różnych podejść do zarządzania współbieżnością: Rust z biblioteką Tokio oraz C++ z mechanizmami standardowej biblioteki i rozszerzeniami języka C++20.

\section{Porównanie międzyjęzykowe}

\subsection{Struktura i organizacja kodu}

\begin{table}[H]
    \centering
    \caption{Porównanie aspektów struktury i organizacji kodu w implementacjach współbieżnych}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust (Tokio)} &
        \textbf{C++ (std::thread + C++20)} \\
        \midrule
        Architektura &
        Modularna, oparta na cechach \eng{traits}, model aktorów &
        Hierarchia klas, szablony \eng{template}, wątek na zadanie \\
        \hline
        Enkapsulacja &
        Moduły i cechy, silna separacja odpowiedzialności &
        Klasy i przestrzenie nazw, możliwość naruszenia enkapsulacji \\
        \hline
        Obsługa błędów &
        \texttt{Result<T,E>} i \texttt{Option<T>} - wymuszona &
        \texttt{std::optional} i wyjątki - opcjonalna \\
        \hline
        Asynchroniczność &
        Wbudowana obsługa \texttt{async/await}, bez kosztów wydajności &
        \texttt{std::async}, \texttt{std::future}, ręczne zarządzanie \\
        \hline
        Bezpieczeństwo typów &
        Gwarantowane w czasie kompilacji, mechanizm pożyczania \eng{borrow checker} &
        Sprawdzanie w czasie wykonania + zewnętrzne narzędzia (np. ThreadSanitizer) \\
        \hline
        Warunkowa kompilacja &
        Atrybuty \texttt{cfg}, flagi cech \eng{feature flags} &
        Makra preprocesora, bloki \texttt{\#ifdef} \\
        \hline
        Kompatybilność &
        Stabilne API, system edycji języka &
        Wiele standardów (C++11/14/17/20/23) \\
        \bottomrule
    \end{tabularx}
\end{table}
Implementacja w języku Rust cechuje się większą spójnością architektoniczną dzięki wbudowanym mechanizmom asynchroniczności oraz systemowi cech \eng{traits}. C++ zapewnia większą elastyczność kosztem złożoności zarządzania zgodnością między różnymi wersjami standardu.


\subsection{Zarządzanie pamięcią}

\begin{table}[H]
    \centering
    \caption{Porównanie modeli zarządzania pamięcią w implementacjach współbieżnych}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust} &
        \textbf{C++} \\
        \midrule
        Model podstawowy &
        Własność \eng{ownership}, automatyczne zarządzanie &
        RAII, inteligentne wskaźniki, ręczne sterowanie cyklem życia \\
        \hline
        Współdzielenie danych &
        \texttt{Arc<T>} — atomowe zliczanie &
        \texttt{std::shared\_ptr<T>} — zliczanie referencji \\
        \hline
        Wycieki pamięci &
        Rzadkie (możliwe cykle w \texttt{Rc}/\texttt{Arc}) &
        Częstsze (brak \texttt{delete}, niezwolnione zasoby) \\
        \hline
        Use-after-free &
        Niemożliwe (mechanizm pożyczania) &
        Możliwe — wymaga narzędzi diagnostycznych \\
        \hline
        Double-free &
        Wykluczone (pojedynczy właściciel) &
        Możliwe (logiczne błędy w RAII) \\
        \hline
        Przepełnienie bufora &
        Chronione w \texttt{Vec<T>} &
        Możliwe przy tablicach surowych \\
        \hline
        Porządek pamięci &
        \texttt{Ordering::Relaxed}, \texttt{Acquire}, \texttt{Release} &
        \texttt{std::memory\_order} \\
        \hline
        Zwalnianie zasobów &
        Automatyczne (\texttt{Drop}) &
        RAII + destruktory, wymaga dyscypliny \\
        \bottomrule
    \end{tabularx}
\end{table}


System własności w języku Rust eliminuje całe klasy błędów pamięciowych na etapie kompilacji. C++ wymaga większej ostrożności programisty oraz wykorzystania narzędzi diagnostycznych.

\subsection{Mechanizmy współbieżności}

\begin{table}[H]
    \centering
    \caption{Porównanie mechanizmów współbieżności w implementacjach Rust i C++}
    \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X}
        \toprule
        \textbf{Mechanizm} &
        \textbf{Rust (Tokio)} &
        \textbf{C++ (std + C++20)} \\
        \midrule
        Model wykonania &
        Planista z kradzieżą zadań \eng{work-stealing}, \\
        wątki M:N &
        Wątki 1:1, planista systemowy \\
        \hline
        Tworzenie zadań &
        \texttt{tokio::spawn(async \{\})} &
        \texttt{std::async(std::launch::async, \dots)} \\
        \hline
        Komunikacja &
        Kanały typowane: \texttt{mpsc}, \texttt{broadcast}, \texttt{oneshot} &
        Kolejki + \texttt{std::condition\_variable} \\
        \hline
        Synchronizacja &
        Asynchroniczne: \texttt{Semaphore}, \texttt{RwLock}, \texttt{Mutex} &
        \texttt{std::mutex}, \texttt{latch}, \texttt{barrier} \\
        \hline
        Operacje I/O &
        Nieblokujące, zdarzeniowe (\texttt{tokio::select!}) &
        Blokujące, jeden wątek na połączenie \\
        \hline
        Obsługa błędów &
        Operator \texttt{?}, wymuszone propagowanie &
        Wyjątki + ręczna obsługa błędów \\
        \hline
        Limity zasobów &
        \texttt{Semaphore::acquire().await} &
        Liczniki atomowe + synchronizacja \\
        \hline
        Zamknięcie aplikacji &
        \texttt{broadcast} + \texttt{select!} &
        \texttt{std::atomic<bool>} + pętla sprawdzająca \\
        \hline
        Wyścigi danych &
        Niemożliwe (cechy \texttt{Send}/\texttt{Sync}) &
        Możliwe — wymaga synchronizacji \\
        \bottomrule
    \end{tabularx}
\end{table}
Porównując mechanizmy współbieżności w językach Rust i C++, można zauważyć fundamentalne różnice w filozofii projektowej i gwarancjach bezpieczeństwa. Rust przyjmuje podejście "bezpieczeństwo przede wszystkim", podczas gdy C++ oferuje większą elastyczność, ale wymaga większej dyscypliny od programisty.

\subsubsection{Rust - kanały typowane}
Implementacja Rust wykorzystuje kanały z różnymi semantykami komunikacji (\texttt{broadcast}):
\begin{lstlisting}[language=Rust, caption={Producent-Konsument w Rust z mpsc channels}, label={lst:rust_producer_consumer}]
fn producer_consumer_channel_benchmark(num_producers: usize, num_consumers: usize, items_per_producer: usize) {
    let metrics = Arc::new(ConcurrencyMetrics::new());
    let (tx, rx) = mpsc::channel();
    let rx = Arc::new(Mutex::new(rx));
    let producers_done = Arc::new(AtomicBool::new(false));
    
    // Producenci
    for i in 0..num_producers {
        let tx = tx.clone();
        let metrics_clone = Arc::clone(&metrics);
        
        let handle = thread::spawn(move || {
            for j in 0..items_per_producer {
                let start_send = Instant::now();
                if tx.send(format!("Producer-{}-Item-{}", i, j)).is_ok() {
                    metrics_clone.increment_produced();
                    metrics_clone.record_channel_operation(start_send.elapsed());
                }
                
                if j % 100 == 0 {
                    thread::sleep(Duration::from_micros(1));
                }
            }
            println!("Rust Producer {} finished", i);
        });
        producer_handles.push(handle);
    }
    
    // Konsumenci
    for i in 0..num_consumers {
        let rx = Arc::clone(&rx);
        let metrics_clone = Arc::clone(&metrics);
        let producers_done_clone = Arc::clone(&producers_done);
        
        let handle = thread::spawn(move || {
            let mut local_consumed = 0;
            loop {
                let start_recv = Instant::now();
                let received = {
                    if let Ok(rx_guard) = rx.try_lock() {
                        match rx_guard.try_recv() {
                            Ok(_item) => {
                                metrics_clone.record_channel_operation(start_recv.elapsed());
                                metrics_clone.increment_consumed();
                                local_consumed += 1;
                                true
                            }
                            Err(mpsc::TryRecvError::Empty) => {
                                if producers_done_clone.load(Ordering::Relaxed) {
                                    break;
                                }
                                false
                            }
                            Err(mpsc::TryRecvError::Disconnected) => break,
                        }
                    } else {
                        false
                    }
                };
                
                if !received {
                    thread::sleep(Duration::from_micros(10));
                }
            }
            println!("Rust Consumer {} finished, consumed {} items", i, local_consumed);
        });
        consumer_handles.push(handle);
    }
    
    drop(tx);
    for handle in producer_handles {
        handle.join().unwrap();
    }
    
    producers_done.store(true, Ordering::Relaxed);
    for handle in consumer_handles {
        handle.join().unwrap();
    }
}
\end{lstlisting}

\subsubsection{C++ - ręczna synchronizacja}
Wersja C++ opiera się na ręcznym zarządzaniu współbieżnością z użyciem mutexów i zmiennych warunkowych:
\begin{lstlisting}[language=C++, caption={Producent-Konsument w C++ z Channel}, label={lst:cpp_producer_consumer}]
template<typename T>
class Channel {
private:
    std::queue<T> queue_;
    mutable std::mutex mutex_;
    std::condition_variable condition_;
    bool closed_ = false;

public:
    void send(T item) {
        std::lock_guard<std::mutex> lock(mutex_);
        if (!closed_) {
            queue_.push(std::move(item));
            condition_.notify_one();
        }
    }

    bool try_recv(T& item) {
        std::unique_lock<std::mutex> lock(mutex_);
        if (queue_.empty()) {
            if (closed_) return false;
            return false;
        }
        item = std::move(queue_.front());
        queue_.pop();
        return true;
    }

    bool recv(T& item) {
        std::unique_lock<std::mutex> lock(mutex_);
        condition_.wait(lock, [this]() { return !queue_.empty() || closed_; });
        
        if (queue_.empty() && closed_) return false;
        
        item = std::move(queue_.front());
        queue_.pop();
        return true;
    }

    void close() {
        std::lock_guard<std::mutex> lock(mutex_);
        closed_ = true;
        condition_.notify_all();
    }
};

void enhanced_producer_consumer_channel_benchmark(std::size_t num_producers, std::size_t num_consumers, std::size_t items_per_producer) {
    auto metrics = std::make_shared<EnhancedConcurrencyMetrics>();
    Channel<std::string> channel;
    std::atomic<bool> producers_done{false};
    
    std::vector<std::thread> producers;
    std::vector<std::thread> consumers;
    
    // Producenci
    for (std::size_t i = 0; i < num_producers; ++i) {
        producers.emplace_back([i, items_per_producer, &channel, metrics]() {
            for (std::size_t j = 0; j < items_per_producer; ++j) {
                auto start_send = std::chrono::steady_clock::now();
                std::string item = "Producer-" + std::to_string(i) + "-Item-" + std::to_string(j);
                channel.send(item);
                metrics->increment_produced();
                auto end_send = std::chrono::steady_clock::now();
                metrics->record_channel_operation(std::chrono::duration_cast<std::chrono::nanoseconds>(end_send - start_send));
                
                if (j % 100 == 0) {
                    std::this_thread::sleep_for(std::chrono::microseconds(1));
                }
            }
            std::cout << "C++ Enhanced Producer " << i << " finished\n";
        });
    }
    
    // Konsumenci
    for (std::size_t i = 0; i < num_consumers; ++i) {
        consumers.emplace_back([i, &channel, &producers_done, metrics]() {
            std::string item;
            std::size_t local_consumed = 0;
            
            while (true) {
                auto start_recv = std::chrono::steady_clock::now();
                bool received = channel.try_recv(item);
                
                if (received) {
                    auto end_recv = std::chrono::steady_clock::now();
                    metrics->record_channel_operation(std::chrono::duration_cast<std::chrono::nanoseconds>(end_recv - start_recv));
                    metrics->increment_consumed();
                    local_consumed++;
                } else {
                    if (producers_done.load() && channel.empty()) {
                        break;
                    }
                    std::this_thread::sleep_for(std::chrono::microseconds(10));
                }
            }
            std::cout << "C++ Enhanced Consumer " << i << " finished, consumed " << local_consumed << " items\n";
        });
    }
    
    for (auto& t : producers) t.join();
    producers_done.store(true);
    
    std::this_thread::sleep_for(std::chrono::milliseconds(10));
    
    for (auto& t : consumers) t.join();
}
\end{lstlisting}

\subsubsection{Serwera echo}

\subsubsection{Rust - wejście/wyjście sterowane zdarzeniami}
Implementacja Rust wykorzystuje nieblokujące I/O:
\begin{lstlisting}[language=Rust, caption={Echo Serwer w Rust z Tokio}, label={lst:rust_echo_server}]
async fn run_echo_server(
    addr: &str, 
    max_connections: usize,
    shutdown_rx: &mut broadcast::Receiver<()>
) -> Arc<EchoServerMetrics> {
    println!("Starting echo server on {}", addr);
    
    let listener = TcpListener::bind(addr).await.expect("Failed to bind");
    let metrics = Arc::new(EchoServerMetrics::new());
    let semaphore = Arc::new(Semaphore::new(max_connections));
    
    println!("Echo server listening on {} (max {} connections)", addr, max_connections);
    
    loop {
        tokio::select! {
            // Handle new connections
            accept_result = listener.accept() => {
                match accept_result {
                    Ok((stream, addr)) => {
                        if let Ok(permit) = semaphore.clone().try_acquire_owned() {
                            let metrics_clone = Arc::clone(&metrics);
                            tokio::spawn(async move {
                                handle_echo_client(stream, addr, metrics_clone).await;
                                drop(permit);
                            });
                        } else {
                            println!("Connection rejected: max capacity reached");
                            drop(stream);
                        }
                    }
                    Err(e) => {
                        eprintln!("Failed to accept connection: {}", e);
                    }
                }
            }
            
            // Handle shutdown signal
            _ = shutdown_rx.recv() => {
                println!("Echo server shutting down...");
                break;
            }
        }
    }
    
    metrics
}

async fn handle_echo_client(
    mut stream: TcpStream, 
    addr: SocketAddr, 
    metrics: Arc<EchoServerMetrics>
) {
    let connection_start = Instant::now();
    let conn_id = metrics.connection_started();
    let mut buffer = [0; 1024];
    let mut total_bytes = 0u64;
    let mut message_count = 0;
    
    println!("Client connected: {} (ID: {})", addr, conn_id);
    
    loop {
        match timeout(Duration::from_secs(30), stream.read(&mut buffer)).await {
            Ok(Ok(0)) => break, // Connection closed
            Ok(Ok(n)) => {
                // Echo the data back
                if stream.write_all(&buffer[0..n]).await.is_err() {
                    break;
                }
                total_bytes += (n * 2) as u64; // Read + write
                message_count += 1;
            }
            Ok(Err(_)) | Err(_) => break, // Error or timeout
        }
    }
    
    let duration = connection_start.elapsed();
    metrics.connection_ended(duration, message_count, total_bytes);
    println!("Client disconnected: {} (ID: {}, {}ms, {} messages, {} bytes)", 
             addr, conn_id, duration.as_millis(), message_count, total_bytes);
}
\end{lstlisting}

\subsubsection{C++ - jeden wątek na połączenie}
Wersja C++ tworzy osobny wątek dla każdego klienta:
\begin{lstlisting}[language=C++, caption={Echo Serwer w C++ z jednym wątkiem na połączenie}, label={lst:cpp_echo_server}]
class EchoServer {
private:
    int server_socket;
    std::atomic<bool> running{true};
    std::shared_ptr<EchoServerMetrics> metrics;
    size_t max_connections;
    std::atomic<size_t> current_connections{0};

public:
    EchoServer(const std::string& address, int port, size_t max_conn) 
        : max_connections(max_conn), metrics(std::make_shared<EchoServerMetrics>()) {
        
        server_socket = socket(AF_INET, SOCK_STREAM, 0);
        if (server_socket < 0) {
            throw std::runtime_error("Failed to create socket");
        }
        
        int opt = 1;
        setsockopt(server_socket, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
        
        sockaddr_in server_addr{};
        server_addr.sin_family = AF_INET;
        server_addr.sin_port = htons(port);
        inet_pton(AF_INET, address.c_str(), &server_addr.sin_addr);
        
        if (bind(server_socket, (sockaddr*)&server_addr, sizeof(server_addr)) < 0) {
            throw std::runtime_error("Failed to bind socket");
        }
        
        if (listen(server_socket, SOMAXCONN) < 0) {
            throw std::runtime_error("Failed to listen on socket");
        }
    }
    
    void run() {
        std::cout << "Echo server listening (max " << max_connections << " connections)\n";
        
        while (running.load(std::memory_order_relaxed)) {
            sockaddr_in client_addr{};
            socklen_t addr_len = sizeof(client_addr);
            
            int client_socket = accept(server_socket, (sockaddr*)&client_addr, &addr_len);
            if (client_socket < 0) {
                if (running.load(std::memory_order_relaxed)) {
                    std::cerr << "Failed to accept connection\n";
                }
                continue;
            }
            
            if (current_connections.load(std::memory_order_relaxed) >= max_connections) {
                std::cout << "Connection rejected: max capacity reached\n";
                close(client_socket);
                continue;
            }
            
            char client_ip[INET_ADDRSTRLEN];
            inet_ntop(AF_INET, &client_addr.sin_addr, client_ip, INET_ADDRSTRLEN);
            std::string client_address = std::string(client_ip) + ":" + std::to_string(ntohs(client_addr.sin_port));
            
            std::thread(&EchoServer::handle_client, this, client_socket, client_address).detach();
        }
    }
    
    void handle_client(int client_socket, const std::string& client_addr) {
        auto connection_start = steady_clock::now();
        auto conn_id = metrics->connection_started();
        current_connections.fetch_add(1, std::memory_order_relaxed);
        
        char buffer[1024];
        uint64_t total_bytes = 0;
        size_t message_count = 0;
        
        std::cout << "Client connected: " << client_addr << " (ID: " << conn_id << ")\n";
        
        while (running.load(std::memory_order_relaxed)) {
            ssize_t bytes_read = recv(client_socket, buffer, sizeof(buffer), 0);
            if (bytes_read <= 0) break;
            
            ssize_t bytes_sent = send(client_socket, buffer, bytes_read, 0);
            if (bytes_sent <= 0) break;
            
            total_bytes += bytes_read + bytes_sent;
            message_count++;
        }
        
        auto duration = duration_cast<microseconds>(steady_clock::now() - connection_start);
        metrics->connection_ended(duration, message_count, total_bytes);
        current_connections.fetch_sub(1, std::memory_order_relaxed);
        
        std::cout << "Client disconnected: " << client_addr 
                  << " (ID: " << conn_id 
                  << ", " << duration_cast<milliseconds>(duration).count() << "ms"
                  << ", " << message_count << " messages"
                  << ", " << total_bytes << " bytes)\n";
        
        close(client_socket);
    }
};
\end{lstlisting}

\subsubsection{C++ - wersja asynchroniczna z epoll/kqueue}
C++ oferuje także asynchroniczną implementację używającą epoll (Linux) lub kqueue (macOS):
\begin{lstlisting}[language=C++, caption={Async Echo Serwer w C++ z event loop}, label={lst:cpp_async_echo_server}]
class AsyncEchoServer {
private:
    int server_socket;
    std::atomic<bool> running{true};
    std::shared_ptr<EchoServerMetrics> metrics;
    size_t max_connections;
    std::atomic<size_t> current_connections{0};
    
#ifdef __APPLE__
    int kqueue_fd;
#else
    int epoll_fd;
#endif

public:
    void run_async() {
        std::cout << "Async Echo server listening (max " << max_connections << " connections)\n";
        
        while (running.load(std::memory_order_relaxed)) {
            std::vector<int> clients_to_remove;
            
#ifdef __APPLE__
            struct kevent events[64];
            struct timespec timeout = {0, 1000000}; // 1ms
            int nev = kevent(kqueue_fd, nullptr, 0, events, 64, &timeout);
            
            for (int i = 0; i < nev; ++i) {
                if ((int)events[i].ident == server_socket) {
                    // New connection
                    sockaddr_in client_addr{};
                    socklen_t addr_len = sizeof(client_addr);
                    
                    int client_socket = accept(server_socket, (sockaddr*)&client_addr, &addr_len);
                    if (client_socket >= 0) {
                        if (current_connections.load(std::memory_order_relaxed) >= max_connections) {
                            std::cout << "Async connection rejected: max capacity reached\n";
                            close(client_socket);
                            continue;
                        }
                        
                        // Set non-blocking
                        int flags = fcntl(client_socket, F_GETFL, 0);
                        fcntl(client_socket, F_SETFL, flags | O_NONBLOCK);
                        
                        // Add to kqueue
                        struct kevent ev;
                        EV_SET(&ev, client_socket, EVFILT_READ, EV_ADD, 0, 0, nullptr);
                        kevent(kqueue_fd, &ev, 1, nullptr, 0, nullptr);
                        
                        // Track connection
                        auto conn_id = metrics->connection_started();
                        current_connections.fetch_add(1, std::memory_order_relaxed);
                    }
                }
            }
#else
            struct epoll_event events[64];
            int nfds = epoll_wait(epoll_fd, events, 64, 1); // 1ms timeout
            
            for (int i = 0; i < nfds; ++i) {
                if (events[i].data.fd == server_socket) {
                    // Handle new connection similar to kqueue version
                } else {
                    // Handle client data
                    int client_socket = events[i].data.fd;
                    
                    if (!handle_client_data(client_socket)) {
                        epoll_ctl(epoll_fd, EPOLL_CTL_DEL, client_socket, nullptr);
                        disconnect_client(client_socket);
                        clients_to_remove.push_back(client_socket);
                    }
                }
            }
#endif
        }
    }
    
    bool handle_client_data(int client_socket) {
        char buffer[1024];
        ssize_t bytes_read = recv(client_socket, buffer, sizeof(buffer), 0);
        
        if (bytes_read > 0) {
            ssize_t bytes_sent = send(client_socket, buffer, bytes_read, 0);
            if (bytes_sent > 0) {
                return true; // Continue processing
            } else {
                return false; // Send failed, disconnect
            }
        } else if (bytes_read == 0 || (bytes_read < 0 && errno != EAGAIN && errno != EWOULDBLOCK)) {
            // Connection closed or error
            return false;
        }
        return true; // EAGAIN/EWOULDBLOCK, continue processing
    }
};
\end{lstlisting}

\subsection{Wydajność i bezpieczeństwo}

\begin{table}[H]
    \centering
    \caption{Porównanie wydajności i bezpieczeństwa implementacji współbieżnych}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Aspekt} &
        \textbf{Rust} &
        \textbf{C++} \\
        \midrule
        Bezpieczeństwo kompilacji &
        Wysokie - system pożyczania eliminuje wyścigi danych &
        Średnie - wymaga zewnętrznych narzędzi (np. ThreadSanitizer) \\
        \hline
        Narzut w czasie wykonania &
        Niski - abstrakcje bezkosztowe \eng{zero-cost} &
        Średni - narzut tworzenia wątków \\
        \hline
        Efektywność pamięci &
        Wysoka - współdzielona własność z \texttt{Arc<T>} &
        Średnia - ryzyko wycieków pamięci \\
        \hline
        Skalowanie &
        Wysokie - model M:N, kradzież zadań &
        Ograniczone - model 1:1, ograniczenia systemowe \\
        \hline
        Odzyskiwanie po błędach &
        Strukturalne - propagacja błędów przez \texttt{Result<T, E>} &
        Oparte na wyjątkach - ryzyko wycieków zasobów \\
        \hline
        Trudność debugowania &
        Średnia - błędy kompilacji z \eng{borrow checker} &
        Wysoka - wyścigi, błędy pamięci \\
        \hline
        Dojrzałość ekosystemu &
        Rozwijający się - Tokio, async-std &
        Dojrzały - OpenMP, TBB, Boost.Asio \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Modele wykonania i zarządzanie zadaniami}

Rust, szczególnie z wykorzystaniem biblioteki Tokio, stosuje zaawansowany model wątków M:N (wiele wątków logicznych na wiele systemowych) wraz z planistą wykorzystującym strategię kradzieży zadań \eng{work-stealing}. Oznacza to, że jeden wątek systemowy może obsługiwać wiele lekkich zadań asynchronicznych, a bezczynne wątki mogą „kraść” zadania od przeciążonych. Taka architektura pozwala na efektywne wykorzystanie zasobów i dobre skalowanie przy dużej liczbie operacji wejścia/wyjścia.

C++ opiera się na tradycyjnym modelu 1:1, w którym każdy wątek logiczny odpowiada jednemu wątkowi systemowemu. Od wersji C++20 dostępny jest typ \texttt{std::jthread}, który automatycznie dołącza wątek w destruktorze, eliminując problem tzw. osieroconych wątków. Niemniej jednak sam model wykonania nie uległ zmianie, co w przypadku dużej liczby równoległych zadań może prowadzić do nieefektywnego zarządzania zasobami systemowymi.

\subsubsection{Komunikacja i synchronizacja}

W języku Rust kanały komunikacyjne stanowią podstawowy mechanizm współpracy między zadaniami. Biblioteka Tokio oraz standardowe moduły oferują kanały o różnych semantykach: \texttt{mpsc} (jednoźródłowy, wielo-odbiorczy), \texttt{broadcast} oraz \texttt{oneshot}. Dzięki systemowi typów i cechom \eng{traits}, komunikacja ta jest bezpieczna zarówno pod względem typów, jak i współbieżności.

W C++ komunikacja między wątkami realizowana jest najczęściej za pomocą współdzielonych struktur danych chronionych przez \texttt{std::mutex} oraz mechanizmów sygnalizujących, takich jak \texttt{std::condition\_variable}. Od C++20 dostępne są dodatkowo \texttt{std::latch} oraz \texttt{std::barrier}, które ułatwiają synchronizację grup wątków. Brakuje jednak wbudowanego odpowiednika kanałów znanych z Rust.

\subsubsection{Obsługa I/O i zarządzanie zasobami}

Ekosystem Tokio w Rust zapewnia w pełni asynchroniczne i nieblokujące operacje wejścia/wyjścia, obsługiwane przez mechanizm multipleksowania zdarzeń oparty na makrze \texttt{select!}. Pozwala to na obsługę tysięcy połączeń przy minimalnej liczbie aktywnych wątków, co ma kluczowe znaczenie dla wydajnych serwerów sieciowych.

Z kolei standardowa biblioteka C++ nie oferuje natywnego wsparcia dla nieblokującego I/O. W rezultacie programiści zmuszeni są korzystać z systemowego API (np. epoll/kqueue) lub bibliotek zewnętrznych (np. Boost.Asio). Częstą praktyką jest tworzenie oddzielnego wątku dla każdego połączenia, co ogranicza skalowanie aplikacji.

\subsubsection{Bezpieczeństwo współbieżności}

Najbardziej zasadnicza różnica między Rust a C++ dotyczy podejścia do bezpieczeństwa współbieżnego. Rust stosuje rygorystyczny system typów oraz cechy \texttt{Send} i \texttt{Sync}, które gwarantują bezpieczeństwo dostępu do danych współdzielonych już na etapie kompilacji. Kompilator odrzuca programy mogące prowadzić do wyścigów danych, co eliminuje całą klasę trudnych do wykrycia błędów.

W C++ bezpieczeństwo współbieżności opiera się na odpowiedzialności programisty. Wszelkie błędy synchronizacji (np. brak blokady, nadmierne współdzielenie danych) mogą prowadzić do wyścigów, które są trudne do wykrycia i debugowania. Choć dostępne są narzędzia analityczne, takie jak ThreadSanitizer, nie eliminują one problemów przed uruchomieniem programu i nie oferują gwarancji podobnych do Rust.



\subsection{Wnioski}

Analiza implementacji ujawnia fundamentalne różnice w podejściu do bezpieczeństwa i wydajności.

\subsubsection{Rust} oferuje bezpieczeństwo "z definicji" poprzez:
\begin{itemize}
    \item System własności eliminujący wyścigi danych na etapie kompilacji
    \item Kanały bezpieczne typowo z różnymi semantykami komunikacji
    \item Bezkosztowe abstrakcje \eng{zero-cost} dla programowania asynchronicznego
    \item Strukturalne zarządzanie błędami, wymuszające ich obsługę
\end{itemize}

\subsubsection{C++} daje większą kontrolę i elastyczność dzięki:
\begin{itemize}
    \item Bezpośredniemu dostępowi do prymitywów systemowych
    \item Możliwości niskopoziomowej optymalizacji wydajności
    \item Dojrzałemu ekosystemowi bibliotek i narzędzi
    \item Zgodności wstecznej ze starszym kodem i różnymi standardami języka
\end{itemize}

W praktyce wybór między językami zależy od priorytetów projektu: bezpieczeństwo vs kontrola, produktywność vs elastyczność, nowoczesność vs kompatybilność. Należy również uwzględnić kompetencje zespołu oraz wymagania środowiska docelowego.


