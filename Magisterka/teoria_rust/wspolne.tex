\section{Mechanizmy wspólne dla współbieżności i równoległości}
\subsection{Wątki (std::thread)}
Jednym z podstawowych narzędzi oferowanych przez standardową bibliotekę Rust jest moduł \texttt{std::thread}, który umożliwia tworzenie niezależnych wątków wykonawczych. Pomimo że zapewnia on niski poziom abstrakcji i bezpośrednią kontrolę nad wątkami, jego użycie wymaga większej ostrożności w kontekście synchronizacji i zarządzania danymi współdzielonymi.
Przykładowa konstrukcja:
\begin{lstlisting}[language=Rust, caption=Przykład tworzenia wątku, label=thread_example]
use std::thread;

fn main() {
    let handle = thread::spawn(|| {
        // kod wykonywany równolegle
    });
    handle.join().unwrap();
}
\end{lstlisting}
W przedstawionym przykładzie listing \ref{thread_example} wykorzystano funkcję \texttt{thread::spawn}, która tworzy nowy wątek wykonawczy, umożliwiając równoległe przetwarzanie danych lub zadań. Ciało funkcji anonimowej przekazanej do spawn zawiera kod, który zostanie wykonany w kontekście nowo utworzonego wątku. Zmienna \texttt{handle} przechowuje uchwyt do tego wątku, umożliwiając synchronizację z jego wykonaniem.
Wywołanie \texttt{handle.join().unwrap()} służy do zablokowania głównego wątku programu do momentu zakończenia pracy wątku potomnego. Metoda \texttt{join} zwraca wynik zakończenia wątku.

Tworzenie dużej liczby wątków może być kosztowne zarówno pod względem zasobów systemowych, jak i czasu inicjalizacji. W związku z tym, Rust oferuje mechanizmy pul wątków \eng{thread pools}, które umożliwiają wielokrotne wykorzystywanie wcześniej zainicjalizowanych wątków do realizacji wielu zadań.

Popularnym rozwiązaniem wspierającym pule wątków jest biblioteka Rayon, która automatyzuje proces zarządzania wątkami w kontekście równoległego przetwarzania danych. Jednakże, również inne biblioteki, takie jak Tokio (dla asynchroniczności) czy async-std, implementują własne menedżery wątków, umożliwiające bardziej zaawansowane zarządzanie zadaniami.

W celu maksymalizacji wykorzystania zasobów obliczeniowych, wiele implementacji pul wątków w Rust stosuje strategię kradzieży zadań \eng{work stealing}. Mechanizm ten polega na dynamicznym równoważeniu obciążenia przez umożliwienie wątkom pobierania zadań z kolejek innych wątków, gdy ich własne kolejki są puste. Zwiększa to ogólną wydajność i skraca czas przetwarzania zadań.

Strategia ta znajduje zastosowanie m.in. w implementacji puli wątków biblioteki Rayon, co czyni ją wysoce wydajną w przypadku zadań o nieregularnym czasie wykonania lub zróżnicowanym poziomie złożoności.

\subsection{Synchronizacja dostępu (Mutex, RwLock)}
Dla sytuacji wymagających współdzielenia pamięci Rust oferuje synchronizowane struktury, takie jak \texttt{Mutex} \eng{mutual exclusion} oraz \texttt{RwLock}. Umożliwiają one zarządzanie dostępem do danych w sposób bezpieczny, jednocześnie wymagając od programisty jawnego określenia momentów blokady i odblokowania zasobów.

\begin{lstlisting}[language=Rust, caption=Przykład użycia Mutex, label=mutex_example]
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));

    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Wartość końcowa: {}", *counter.lock().unwrap());
}
\end{lstlisting}
\texttt{Mutex<T>} \eng{mutual exclusion}, czyli wzajemne wykluczanie, to mechanizm blokady umożliwiający bezpieczny dostęp do danych przez wiele wątków. W powyższym przykładzie dane typu \texttt{i32} są opakowane w \texttt{Mutex}, a następnie udostępniane wielu wątkom za pomocą wskaźnika liczony atomowo \texttt{Arc<T>}. Każdy wątek dokonuje inkrementacji zmiennej wewnątrz sekcji krytycznej, co zapobiega wyścigom danych. Wywołanie \texttt{lock().unwrap()} blokuje wątek do czasu uzyskania wyłącznego dostępu do danych. Podejście to jest typowe w programowaniu zarówno współbieżnym (dla ochrony stanu globalnego), jak i równoległym (dla synchronizacji wyników obliczeń). 

\begin{lstlisting}[language=Rust, caption=Przykład użycia RwLock, label=rwlock_example]
use std::sync::{Arc, RwLock};
use std::thread;

fn main() {
    let data = Arc::new(RwLock::new(vec![1, 2, 3]));

    let reader = {
        let data = Arc::clone(&data);
        thread::spawn(move || {
            let read = data.read().unwrap();
            println!("Odczyt danych: {:?}", *read);
        })
    };

    let writer = {
        let data = Arc::clone(&data);
        thread::spawn(move || {
            let mut write = data.write().unwrap();
            write.push(4);
        })
    };

    reader.join().unwrap();
    writer.join().unwrap();
}
\end{lstlisting}
RwLock<T> \eng{read-write lock} czyli blokada odczytu-zapisu, umożliwia wielu wątkom jednoczesny odczyt danych przy zachowaniu wyłączności dla operacji zapisu. W przypadku często czytanych, rzadko modyfikowanych danych, takie rozwiązanie pozwala na lepszą wydajność niż klasyczny \texttt{Mutex}. Biblioteka standardowa Rust zapewnia gwarancje bezpieczeństwa pamięci, eliminując ryzyko naruszeń spójności danych nawet w środowiskach wielordzeniowych.  
\subsection{Wartości atomowe (Atomic)}

Rust obsługuje także operacje na typach atomowych, które pozwalają na wykonywanie niepodzielnych operacji na współdzielonych zmiennych bez potrzeby stosowania bardziej zaawansowanych mechanizmów synchronizacji.

\begin{lstlisting}[language=Rust, caption=Przykład użycia Atomic, label=atomic_example]
use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;

fn main() {
    let counter = AtomicUsize::new(0);

    let handles: Vec<_> = (0..10)
        .map(|_| {
            let counter_ref = &counter;
            thread::spawn(move || {
                for _ in 0..1000 {
                    counter_ref.fetch_add(1, Ordering::Relaxed);
                }
            })
        })
        .collect();

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Wynik: {}", counter.load(Ordering::Relaxed));
}
\end{lstlisting}
Typy \texttt{Atomic} w Rust, takie jak \texttt{AtomicUsize}, \texttt{AtomicBool}, czy \texttt{AtomicPtr}, umożliwiają bezpieczne operacje na danych współdzielonych bez stosowania mechanizmów blokujących \eng{lock-free synchronization}. W przedstawionym przykładzie listing \ref{atomic_example}, funkcja \texttt{fetch\_add} wykonuje inkrementację wartości w sposób atomowy, zapewniając spójność danych nawet przy równoczesnym dostępie z wielu wątków. Choć \texttt{Ordering::Relaxed} zapewnia najmniejszy narzut, istnieją też silniejsze modele spójności pamięci (np. \texttt{SeqCst}, \texttt{Acquire/Release}), które mogą być konieczne przy bardziej złożonych zależnościach.

\subsection{Bariery}
Rust oferuje również podstawowe prymitywy synchronizacyjne, takie jak bariery, które umożliwiają synchronizację wątków w bardziej złożonych scenariuszach. Bariery pozwalają na zsynchronizowanie grupy wątków, które muszą osiągnąć określony punkt przed kontynuowaniem pracy, natomiast semafory kontrolują dostęp do ograniczonej liczby zasobów.
\begin{lstlisting}[language=Rust, caption=Przykład użycia bariery, label=barrier_example]
use std::sync::{Arc, Barrier};
use std::thread;

fn main() {
    let barrier = Arc::new(Barrier::new(3));
    let mut handles = vec![];

    for i in 0..3 {
        let c = Arc::clone(&barrier);
        let handle = thread::spawn(move || {
            println!("Wątek {}: przed barierą", i);
            c.wait(); // punkt synchronizacji
            println!("Wątek {}: po barierze", i);
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }
}
\end{lstlisting}
Barrier (bariera synchronizacyjna) to mechanizm służący do synchronizacji wielu wątków w~ustalonym punkcie programu. Każdy wątek, który osiąga barierę, zostaje zablokowany do momentu, aż dojdą do niej wszystkie pozostałe wątki zadeklarowane przy jej utworzeniu. Przykład ten przedstawia trójwątkową synchronizację - żaden z wątków nie przejdzie do fazy po barierze, dopóki wszystkie nie osiągną funkcji \texttt{wait()}. Bariera jest przydatna w systemach opartych na etapowym przetwarzaniu, np. w modelu SIMD czy w systemach obliczeń wielofazowych.